{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "402d6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d5b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37f6e121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cod_cmd</th>\n",
       "      <th>Libellé produit</th>\n",
       "      <th>Vendeur</th>\n",
       "      <th>Univers</th>\n",
       "      <th>Nature</th>\n",
       "      <th>Date de commande</th>\n",
       "      <th>Montant cmd</th>\n",
       "      <th>Quantité</th>\n",
       "      <th>Prix transport</th>\n",
       "      <th>Délai transport annoncé</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>476492</th>\n",
       "      <td>181217541</td>\n",
       "      <td>Matelas ressorts 140x190 cm</td>\n",
       "      <td>Vendeur 1</td>\n",
       "      <td>Bureau Rangement</td>\n",
       "      <td>Meuble à chaussures</td>\n",
       "      <td>03/01/2021 00:00</td>\n",
       "      <td>1 148</td>\n",
       "      <td>1</td>\n",
       "      <td>24,17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244042</th>\n",
       "      <td>184970381</td>\n",
       "      <td>Tapis grafic bleu doré 160x230cm</td>\n",
       "      <td>Autre vendeur</td>\n",
       "      <td>Décoration Textile</td>\n",
       "      <td>Tapis de Salon et Ch</td>\n",
       "      <td>22/02/2021 00:00</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497960</th>\n",
       "      <td>183149730</td>\n",
       "      <td>Meuble haut 80 cm 2 portes</td>\n",
       "      <td>Vendeur 1</td>\n",
       "      <td>Cuisine Salle de bain</td>\n",
       "      <td>Meuble haut cuisine</td>\n",
       "      <td>30/01/2021 00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523356</th>\n",
       "      <td>211101833</td>\n",
       "      <td>Expresso portionné</td>\n",
       "      <td>Vendeur 1</td>\n",
       "      <td>Petit Electroménager</td>\n",
       "      <td>Expresso</td>\n",
       "      <td>31/03/2021 00:00</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>6,66</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167710</th>\n",
       "      <td>185414853</td>\n",
       "      <td>Placard de bureau en métal meuble de rangement...</td>\n",
       "      <td>Autre vendeur</td>\n",
       "      <td>Bureau Rangement</td>\n",
       "      <td>Rangement bureau</td>\n",
       "      <td>02/03/2021 00:00</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468405</th>\n",
       "      <td>181471057</td>\n",
       "      <td>Canapé d angle convertible réversible 4 places...</td>\n",
       "      <td>Vendeur 1</td>\n",
       "      <td>Canapé Salon Séjour</td>\n",
       "      <td>Canapé d'angle</td>\n",
       "      <td>07/01/2021 00:00</td>\n",
       "      <td>802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263900</th>\n",
       "      <td>185728152</td>\n",
       "      <td>Bibliothèque 6 cases</td>\n",
       "      <td>Vendeur 1</td>\n",
       "      <td>Bureau Rangement</td>\n",
       "      <td>Bibliotheque</td>\n",
       "      <td>07/03/2021 00:00</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462917</th>\n",
       "      <td>181311058</td>\n",
       "      <td>Miroir 52 cm</td>\n",
       "      <td>Vendeur 1</td>\n",
       "      <td>Décoration Textile</td>\n",
       "      <td>Miroir</td>\n",
       "      <td>05/01/2021 00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513477</th>\n",
       "      <td>186481160</td>\n",
       "      <td>Armoire 4 portes</td>\n",
       "      <td>Vendeur 1</td>\n",
       "      <td>Chambre Literie</td>\n",
       "      <td>Armoire</td>\n",
       "      <td>20/03/2021 00:00</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68769</th>\n",
       "      <td>186035998</td>\n",
       "      <td>Ensemble table et chaises contemporain ch ne c...</td>\n",
       "      <td>Autre vendeur</td>\n",
       "      <td>Cuisine Salle de bain</td>\n",
       "      <td>Ens table chaises</td>\n",
       "      <td>13/03/2021 00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>16,58</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Cod_cmd                                    Libellé produit  \\\n",
       "476492  181217541                        Matelas ressorts 140x190 cm   \n",
       "244042  184970381                   Tapis grafic bleu doré 160x230cm   \n",
       "497960  183149730                         Meuble haut 80 cm 2 portes   \n",
       "523356  211101833                                 Expresso portionné   \n",
       "167710  185414853  Placard de bureau en métal meuble de rangement...   \n",
       "468405  181471057  Canapé d angle convertible réversible 4 places...   \n",
       "263900  185728152                               Bibliothèque 6 cases   \n",
       "462917  181311058                                       Miroir 52 cm   \n",
       "513477  186481160                                   Armoire 4 portes   \n",
       "68769   186035998  Ensemble table et chaises contemporain ch ne c...   \n",
       "\n",
       "              Vendeur                Univers                Nature  \\\n",
       "476492      Vendeur 1       Bureau Rangement   Meuble à chaussures   \n",
       "244042  Autre vendeur     Décoration Textile  Tapis de Salon et Ch   \n",
       "497960      Vendeur 1  Cuisine Salle de bain   Meuble haut cuisine   \n",
       "523356      Vendeur 1   Petit Electroménager              Expresso   \n",
       "167710  Autre vendeur       Bureau Rangement      Rangement bureau   \n",
       "468405      Vendeur 1    Canapé Salon Séjour        Canapé d'angle   \n",
       "263900      Vendeur 1       Bureau Rangement          Bibliotheque   \n",
       "462917      Vendeur 1     Décoration Textile                Miroir   \n",
       "513477      Vendeur 1        Chambre Literie               Armoire   \n",
       "68769   Autre vendeur  Cuisine Salle de bain     Ens table chaises   \n",
       "\n",
       "        Date de commande  Montant cmd   Quantité Prix transport  \\\n",
       "476492  03/01/2021 00:00        1 148          1          24,17   \n",
       "244042  22/02/2021 00:00          131          1              0   \n",
       "497960  30/01/2021 00:00           15          1              0   \n",
       "523356  31/03/2021 00:00           61          1           6,66   \n",
       "167710  02/03/2021 00:00          163          1              0   \n",
       "468405  07/01/2021 00:00          802          1              0   \n",
       "263900  07/03/2021 00:00           75          1              0   \n",
       "462917  05/01/2021 00:00           21          1              0   \n",
       "513477  20/03/2021 00:00          283          1              0   \n",
       "68769   13/03/2021 00:00          290          1          16,58   \n",
       "\n",
       "        Délai transport annoncé  \n",
       "476492                      NaN  \n",
       "244042                      4.0  \n",
       "497960                      NaN  \n",
       "523356                      4.0  \n",
       "167710                      8.0  \n",
       "468405                      NaN  \n",
       "263900                      0.0  \n",
       "462917                      NaN  \n",
       "513477                      0.0  \n",
       "68769                      33.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73f19831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404939"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cod_cmd'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3788422c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique products: 56018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Libellé produit</th>\n",
       "      <th>Univers</th>\n",
       "      <th>Nature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40 742 ensemble 5 en 1 tondeuse et regle barb...</td>\n",
       "      <td>Petit Electroménager</td>\n",
       "      <td>Tondeuse multistyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60cm fronton applique mural style arbre de vi...</td>\n",
       "      <td>Décoration Textile</td>\n",
       "      <td>Objet deco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9 vip pets vague 1</td>\n",
       "      <td>Enfant Bébé</td>\n",
       "      <td>Poupée et poupon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agère murale hwc h37 étagère suspendue tiroir...</td>\n",
       "      <td>Canapé Salon Séjour</td>\n",
       "      <td>Etagère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allan canapé 3 places convertible ouverture e...</td>\n",
       "      <td>Petit Electroménager</td>\n",
       "      <td>Friteuse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Libellé produit               Univers  \\\n",
       "0   40 742 ensemble 5 en 1 tondeuse et regle barb...  Petit Electroménager   \n",
       "1   60cm fronton applique mural style arbre de vi...    Décoration Textile   \n",
       "2                                 9 vip pets vague 1           Enfant Bébé   \n",
       "3   agère murale hwc h37 étagère suspendue tiroir...   Canapé Salon Séjour   \n",
       "4   allan canapé 3 places convertible ouverture e...  Petit Electroménager   \n",
       "\n",
       "                Nature  \n",
       "0  Tondeuse multistyle  \n",
       "1           Objet deco  \n",
       "2     Poupée et poupon  \n",
       "3              Etagère  \n",
       "4             Friteuse  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most common Univers and Nature for each product\n",
    "product_categories = df.groupby('Libellé produit').agg({\n",
    "    'Univers': lambda x: x.mode().iat[0] if not x.mode().empty else None,\n",
    "    'Nature': lambda x: x.mode().iat[0] if not x.mode().empty else None\n",
    "}).reset_index()\n",
    "\n",
    "df_unique_products = product_categories[['Libellé produit', 'Univers', 'Nature']]\n",
    "\n",
    "print(\"Number of unique products:\", len(df_unique_products))\n",
    "df_unique_products.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80d1f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_products.to_csv('unique_products.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a24a929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Libellé produit</th>\n",
       "      <th>Univers</th>\n",
       "      <th>Nature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32485</th>\n",
       "      <td>Meuble a chaussures boots meuble a chaussures ...</td>\n",
       "      <td>Bureau Rangement</td>\n",
       "      <td>Meuble à chaussures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>Cadre de lit en métal robuste sommier à lattes...</td>\n",
       "      <td>Chambre Literie</td>\n",
       "      <td>Lit adulte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49063</th>\n",
       "      <td>Table à manger extensible renee</td>\n",
       "      <td>Canapé Salon Séjour</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48163</th>\n",
       "      <td>Table de bar avec rangement table bistro haut ...</td>\n",
       "      <td>Canapé Salon Séjour</td>\n",
       "      <td>Table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43162</th>\n",
       "      <td>Sa790141 joint 4 5 6l 220mm pour autocuiseur seb</td>\n",
       "      <td>Petit Electroménager</td>\n",
       "      <td>Pièces détachées</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43361</th>\n",
       "      <td>Salon de jardin cordoue en résine tressée gris...</td>\n",
       "      <td>Jardin Loisirs Sport</td>\n",
       "      <td>Salon de jardin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21522</th>\n",
       "      <td>Icaverne etagères et casiers à chaussures gamm...</td>\n",
       "      <td>Bureau Rangement</td>\n",
       "      <td>Porte chaussures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>Auna krcd 150 radio encastrable lecteur cd usb...</td>\n",
       "      <td>TV Son Multimédia</td>\n",
       "      <td>Radio reveil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20579</th>\n",
       "      <td>Hotte décorative murale 90cm 55db 721m3 h inox...</td>\n",
       "      <td>Gros Electroménager</td>\n",
       "      <td>Hotte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14035</th>\n",
       "      <td>Domy table basse relevable extensible papier d...</td>\n",
       "      <td>Canapé Salon Séjour</td>\n",
       "      <td>Table basse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Libellé produit  \\\n",
       "32485  Meuble a chaussures boots meuble a chaussures ...   \n",
       "7790   Cadre de lit en métal robuste sommier à lattes...   \n",
       "49063                    Table à manger extensible renee   \n",
       "48163  Table de bar avec rangement table bistro haut ...   \n",
       "43162   Sa790141 joint 4 5 6l 220mm pour autocuiseur seb   \n",
       "43361  Salon de jardin cordoue en résine tressée gris...   \n",
       "21522  Icaverne etagères et casiers à chaussures gamm...   \n",
       "4283   Auna krcd 150 radio encastrable lecteur cd usb...   \n",
       "20579  Hotte décorative murale 90cm 55db 721m3 h inox...   \n",
       "14035  Domy table basse relevable extensible papier d...   \n",
       "\n",
       "                    Univers               Nature  \n",
       "32485      Bureau Rangement  Meuble à chaussures  \n",
       "7790        Chambre Literie           Lit adulte  \n",
       "49063   Canapé Salon Séjour                Table  \n",
       "48163   Canapé Salon Séjour                Table  \n",
       "43162  Petit Electroménager     Pièces détachées  \n",
       "43361  Jardin Loisirs Sport      Salon de jardin  \n",
       "21522      Bureau Rangement     Porte chaussures  \n",
       "4283      TV Son Multimédia         Radio reveil  \n",
       "20579   Gros Electroménager                Hotte  \n",
       "14035   Canapé Salon Séjour          Table basse  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('unique_products.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6c42fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Nature'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"tokenizers\", \"scikit-learn\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2098aa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Trained BPE tokenizer with vocab size: 20000 and saved to ./artifacts/bpe_tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.normalizers import NFD, Lowercase, StripAccents, Sequence\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure df is loaded (from earlier cells). Expect columns: 'Libellé produit', 'Nature'\n",
    "assert 'df' in globals(), \"DataFrame df must be loaded earlier.\"\n",
    "assert {'Libellé produit','Nature'}.issubset(df.columns), \"df must have 'Libellé produit' and 'Nature' columns\"\n",
    "\n",
    "# Use the deduplicated products if available\n",
    "if 'df_unique_products' in globals():\n",
    "    data_df = df_unique_products.rename(columns={'Libellé produit': 'label', 'Nature': 'target'})\n",
    "else:\n",
    "    data_df = df.rename(columns={'Libellé produit': 'label', 'Nature': 'target'})[['label','target']].dropna()\n",
    "\n",
    "# Basic cleaning: drop rows with missing or empty labels/targets\n",
    "data_df = data_df.dropna(subset=['label','target'])\n",
    "data_df = data_df[(data_df['label'].astype(str).str.strip()!='') & (data_df['target'].astype(str).str.strip()!='')]\n",
    "\n",
    "# Prepare corpus for BPE\n",
    "corpus = data_df['label'].astype(str).tolist()\n",
    "\n",
    "# Initialize BPE tokenizer\n",
    "bpe_tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "bpe_tokenizer.normalizer = Sequence([NFD(), Lowercase(), StripAccents()])\n",
    "bpe_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# Special tokens and training\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\"]\n",
    "trainer = BpeTrainer(vocab_size=20000, min_frequency=2, special_tokens=special_tokens)\n",
    "\n",
    "bpe_tokenizer.train_from_iterator(corpus, trainer=trainer)\n",
    "\n",
    "# Post-processor for consistent BOS/EOS if desired (not necessary for bag-of-tokens)\n",
    "bpe_tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"$0\",\n",
    "    pair=\"$A $B\",\n",
    "    special_tokens=[(\"[PAD]\", 0), (\"[UNK]\", 1)]\n",
    ")\n",
    "\n",
    "# Save to disk to reuse later\n",
    "bpe_dir = \"./artifacts\"\n",
    "os.makedirs(bpe_dir, exist_ok=True)\n",
    "bpe_path = os.path.join(bpe_dir, \"bpe_tokenizer.json\")\n",
    "bpe_tokenizer.save(bpe_path)\n",
    "\n",
    "print(f\"Trained BPE tokenizer with vocab size: {bpe_tokenizer.get_vocab_size()} and saved to {bpe_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282714e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary mapping from tokenizer\n",
    "vocab = bpe_tokenizer.get_vocab()\n",
    "# Invert mapping to get id->token if needed\n",
    "id_to_token = {idx: tok for tok, idx in vocab.items()}\n",
    "\n",
    "# Helper: encode to BPE token ids, ignoring specials\n",
    "SPECIAL_IDS = {vocab.get(\"[PAD]\"), vocab.get(\"[UNK]\")}\n",
    "\n",
    "def bpe_tokenize(text: str):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text) if text is not None else \"\"\n",
    "    encoding = bpe_tokenizer.encode(text)\n",
    "    # Return tokens (strings) excluding specials\n",
    "    tokens = [t for t in encoding.tokens if vocab.get(t) not in SPECIAL_IDS]\n",
    "    return tokens\n",
    "\n",
    "# Create bag-of-BPE-token counts\n",
    "from collections import Counter\n",
    "\n",
    "all_tokens = []\n",
    "for t in data_df['label'].tolist():\n",
    "    all_tokens.extend(bpe_tokenize(t))\n",
    "\n",
    "# Select top-k tokens to form features\n",
    "from collections import Counter\n",
    "freqs = Counter(all_tokens)\n",
    "max_features = 50000\n",
    "most_common_tokens = [tok for tok, _ in freqs.most_common(max_features)]\n",
    "feature_index = {tok: i for i, tok in enumerate(most_common_tokens)}\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "rows, cols, vals = [], [], []\n",
    "for row_idx, text in enumerate(data_df['label'].tolist()):\n",
    "    counts = Counter(bpe_tokenize(text))\n",
    "    for tok, c in counts.items():\n",
    "        col_idx = feature_index.get(tok)\n",
    "        if col_idx is not None:\n",
    "            rows.append(row_idx)\n",
    "            cols.append(col_idx)\n",
    "            vals.append(c)\n",
    "\n",
    "X = csr_matrix((vals, (rows, cols)), shape=(len(data_df), len(feature_index)), dtype=np.float64)\n",
    "y = data_df['target'].astype(str).values\n",
    "\n",
    "# Robust split handling rare classes (count < 2)\n",
    "counts = pd.Series(y).value_counts()\n",
    "freq_classes = counts[counts >= 2].index\n",
    "frequent_mask = np.isin(y, freq_classes)\n",
    "idx_frequent = np.where(frequent_mask)[0]\n",
    "idx_rare = np.where(~frequent_mask)[0]\n",
    "\n",
    "if len(idx_frequent) >= 2:\n",
    "    X_f = X[idx_frequent]\n",
    "    y_f = y[idx_frequent]\n",
    "    try:\n",
    "        X_train_f, X_test, y_train_f, y_test = train_test_split(\n",
    "            X_f, y_f, test_size=0.1, random_state=42, stratify=y_f\n",
    "        )\n",
    "    except ValueError:\n",
    "        X_train_f, X_test, y_train_f, y_test = train_test_split(\n",
    "            X_f, y_f, test_size=0.1, random_state=42, shuffle=True, stratify=None\n",
    "        )\n",
    "    # Add all rare-class samples to training set\n",
    "    if len(idx_rare) > 0:\n",
    "        X_train = vstack([X_train_f, X[idx_rare]])\n",
    "        y_train = np.concatenate([y_train_f, y[idx_rare]])\n",
    "    else:\n",
    "        X_train, y_train = X_train_f, y_train_f\n",
    "else:\n",
    "    # Fallback: no stratification possible\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=42, shuffle=True, stratify=None\n",
    "    )\n",
    "\n",
    "# Fit Multinomial Naive Bayes\n",
    "nb = MultinomialNB(alpha=0.1)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "print('Train size:', X_train.shape, 'Test size:', X_test.shape)\n",
    "print('Classes:', nb.classes_.shape)\n",
    "print('Test accuracy:', nb.score(X_test, y_test))\n",
    "print(classification_report(y_test, nb.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25c7eb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40 742 ensemble 5 en 1 tondeuse et regle barbe rechargeable\n",
      "Tondeuse multistyle: 0.9889\n",
      "Coiffeuse: 0.0053\n",
      "Accessoire pem: 0.0015\n",
      "Accessoire ch adulte: 0.0010\n",
      "Petit meuble séjour: 0.0007\n",
      "Ens table chaises: 0.0006\n",
      "Evier: 0.0003\n",
      "Chevet: 0.0003\n",
      "Bar: 0.0002\n",
      "Rangement bureau: 0.0001\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "# Prepare structures for prediction\n",
    "class_names = nb.classes_.tolist()\n",
    "class_index = {c: i for i, c in enumerate(class_names)}\n",
    "\n",
    "\n",
    "def vectorize_labels(texts):\n",
    "    rows, cols, vals = [], [], []\n",
    "    for row_idx, text in enumerate(texts):\n",
    "        counts = Counter(bpe_tokenize(text))\n",
    "        for tok, c in counts.items():\n",
    "            col_idx = feature_index.get(tok)\n",
    "            if col_idx is not None:\n",
    "                rows.append(row_idx)\n",
    "                cols.append(col_idx)\n",
    "                vals.append(c)\n",
    "    return csr_matrix((vals, (rows, cols)), shape=(len(texts), len(feature_index)), dtype=np.float64)\n",
    "\n",
    "\n",
    "def predict_nature_proba(label_text: str) -> Dict[str, float]:\n",
    "    Xq = vectorize_labels([label_text])\n",
    "    proba = nb.predict_proba(Xq)[0]\n",
    "    return {cls: float(prob) for cls, prob in zip(class_names, proba)}\n",
    "\n",
    "# Example usage\n",
    "example_label = data_df['label'].iloc[0]\n",
    "probs = predict_nature_proba(example_label)\n",
    "print(example_label)\n",
    "# Display top-10 predicted Natures\n",
    "for cls, p in sorted(probs.items(), key=lambda kv: kv[1], reverse=True)[:10]:\n",
    "    print(f\"{cls}: {p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Train on full data to score items\n",
    "nb_full = MultinomialNB(alpha=0.1)\n",
    "nb_full.fit(X, y)\n",
    "\n",
    "class_names_full = nb_full.classes_.tolist()\n",
    "\n",
    "\n",
    "def score_items_and_find_mislabels(\n",
    "    df_labels_targets: pd.DataFrame,\n",
    "    prob_threshold: float = 0.2,\n",
    "    topk: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify potential mislabelled items by scoring each label with the trained model.\n",
    "\n",
    "    - prob_threshold: if model's probability for the current label's target is below this, flag as candidate.\n",
    "    - topk: include top-k alternative class suggestions and their probabilities.\n",
    "    \"\"\"\n",
    "    texts = df_labels_targets['label'].astype(str).tolist()\n",
    "    X_all = vectorize_labels(texts)\n",
    "    proba_all = nb_full.predict_proba(X_all)\n",
    "    pred_all = nb_full.predict(X_all)\n",
    "\n",
    "    # Map true target index in classes\n",
    "    class_index_full = {c: i for i, c in enumerate(class_names_full)}\n",
    "\n",
    "    rows = []\n",
    "    for i, (label_text, true_cls) in enumerate(zip(df_labels_targets['label'], df_labels_targets['target'])):\n",
    "        probs = proba_all[i]\n",
    "        true_idx = class_index_full.get(str(true_cls), None)\n",
    "        true_prob = float(probs[true_idx]) if true_idx is not None else np.nan\n",
    "        top_indices = np.argsort(probs)[::-1][:topk]\n",
    "        top_suggestions = [(class_names_full[j], float(probs[j])) for j in top_indices]\n",
    "        is_mislabel = (not np.isnan(true_prob)) and (true_prob < prob_threshold)\n",
    "        rows.append({\n",
    "            'label': label_text,\n",
    "            'true_nature': true_cls,\n",
    "            'true_prob': true_prob,\n",
    "            'pred_nature': pred_all[i],\n",
    "            'pred_prob': float(np.max(probs)),\n",
    "            'top_suggestions': top_suggestions,\n",
    "            'candidate_mislabel': bool(is_mislabel),\n",
    "        })\n",
    "\n",
    "    result = pd.DataFrame(rows)\n",
    "    return result.sort_values(['candidate_mislabel','true_prob'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "mislabel_df = score_items_and_find_mislabels(data_df, prob_threshold=0.2, topk=5)\n",
    "print('Candidates:', mislabel_df['candidate_mislabel'].sum(), 'of', len(mislabel_df))\n",
    "mislabel_path = './artifacts/mislabel_candidates.csv'\n",
    "mislabel_df.to_csv(mislabel_path, index=False)\n",
    "print('Saved to', mislabel_path)\n",
    "\n",
    "# Show a preview of flagged items\n",
    "mislabel_df[mislabel_df['candidate_mislabel']].head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
